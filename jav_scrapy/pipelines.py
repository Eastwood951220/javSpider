# jav_scrapy/pipelines.py
from itemadapter import ItemAdapter
from scrapy.exceptions import DropItem

from db.mongo import MongoDBManager
from logs.manager import get_logger

class MongoPipeline:
    """Pipelineï¼šä½¿ç”¨ MongoDBManager åŠ¨æ€ collectionï¼Œä»…å­˜å‚¨ Item"""

    def __init__(self):
        self.mongo: MongoDBManager = None
        self.logger = get_logger("MongoPipeline", console=True, file=False)

    def open_spider(self, spider):
        """çˆ¬è™«å¯åŠ¨æ—¶åˆå§‹åŒ– MongoDB"""
        self.mongo = MongoDBManager()
        self.logger.info(f"ğŸŸ¢ çˆ¬è™«å¯åŠ¨: {spider.name}")

    def process_item(self, item, spider):
        """å¤„ç†æ¯ä¸ª Item"""
        adapter = ItemAdapter(item)
        name = adapter.get("name")
        code = adapter.get("code")

        if not name or not code:
            raise DropItem(f"âŒ ç¼ºå°‘å¿…è¦å­—æ®µ: {item}")

        # åŠ¨æ€ collection_name
        collection_name = name.replace(" ", "_")


        # æ’å…¥ MongoDB
        try:
            self.mongo.insert_if_not_exists(collection_name, dict(adapter), unique_field="code")
            self.logger.info(f"ğŸ“¦ æ–°å¢æˆåŠŸ: {name} | {code}")
        except Exception as e:
            self.logger.error(f"âŒ æ’å…¥å¤±è´¥: {name} | {code} - {e}")

        return item

    def close_spider(self, spider):
        """çˆ¬è™«å…³é—­æ—¶å…³é—­ MongoDB"""
        self.logger.info(f"ğŸ”´ çˆ¬è™«ç»“æŸ: {spider.name}")
        if self.mongo:
            self.mongo.close()
